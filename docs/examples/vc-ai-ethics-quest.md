# Case Study: Developing an AI Investment Ethics Framework

*A VC Partner's 90-Day Quest*

---

## Background

**Role:** Senior Partner at mid-stage VC fund  
**Challenge:** The fund was seeing increasing AI deals but lacked a systematic way to evaluate ethical considerations alongside financial metrics  
**Timing:** Q2 2024, during the AI investment boom  

### The Problem
- Deal flow included many AI startups with varying levels of ethical awareness
- Limited framework for assessing long-term reputational and regulatory risks
- Portfolio companies asking for guidance on responsible AI development
- Need to differentiate the fund's approach in a crowded market

---

## The Quest

**Quest Title:** "Develop a framework for evaluating AI investments that prioritizes ethical considerations alongside financial returns"

**Duration:** 12 weeks  
**Primary Audience:** VC partners and portfolio company founders  
**Success Criteria:** 
- Usable framework tested on 5+ deals
- Positive feedback from 3 portfolio company CEOs
- At least 10 LinkedIn posts documenting the journey
- Framework referenced by industry peers

---

## Process: LBEiP in Action

### Week 1-2: Declaration & Initial Learning (Sanctuary + Stage)

**Sanctuary Session (Monday, Week 1):**
- 90 minutes with notebook, mapping out key ethical considerations in AI
- Identified tensions between innovation speed and safety
- Listed stakeholders: users, society, regulators, investors, founders

**First Public Post (Thursday, Week 1):**
```
I'm starting a 12-week Quest to develop a framework for 
ethical AI investment evaluation.

Current challenge: Amazing AI deals coming through, but 
how do we systematically evaluate ethical risks alongside 
returns?

I'll be sharing my research, conversations, and framework 
development here. Not claiming to have answers‚Äîbut committed 
to asking better questions.

If you're working on responsible AI investment or development, 
I'd love your perspectives.

#VentureCapital #AIEthics #ResponsibleInvesting
```

**Engagement:** 47 likes, 12 thoughtful comments, 3 DMs from other investors

### Week 3-4: Deep Learning Phase

**Research Sources:**
- Partnership on AI guidelines
- EU AI Act documentation  
- Conversations with 3 portfolio company CTOs
- Academic papers on algorithmic bias
- Interview with AI ethics researcher at Stanford

**Learning Post (Week 3):**
```
Week 3 of my AI ethics framework Quest.

Plot twist: The biggest risk isn't "AI going rogue"‚Äîit's 
the gradual erosion of trust through biased outcomes.

Three insights so far:
üîç Most AI ethical issues are actually data issues
üîç Regulatory compliance is table stakes, not differentiation  
üîç The best founders are already thinking about this

Currently reading: "Weapons of Math Destruction" and 
diving into the EU AI Act.

What am I missing in my research?
```

### Week 5-7: Building Phase (Studio + Stage)

**Studio Work:**
- Created 2x2 matrix: High/Low Technical Risk vs High/Low Social Impact
- Developed questionnaire for founder interviews
- Built decision tree for different AI application types

**Construction Post (Week 6):**
```
Building phase of my AI ethics framework.

Wrestling with a key tension: How detailed vs. how practical?

Current thinking: A modular approach
üìä Core principles (applies to all AI deals)
üìä Application-specific deep dives (computer vision, NLP, etc.)
üìä Founder readiness assessment

Here's my rough framework [attached diagram]:

This is messy and incomplete, but that's the point. 
Real frameworks aren't born polished.

Where do you see gaps? What would make this more useful?
```

**Framework Evolution:**
- Week 5: Basic 2x2 matrix
- Week 6: Added founder assessment component  
- Week 7: Included regulatory compliance checklist

### Week 8-10: Testing & Refinement

**Real-World Testing:**
- Applied framework to 3 live deals in pipeline
- Presented to investment committee
- Shared draft with 2 portfolio company CEOs for feedback

**Key Feedback:**
- "Too academic" - needed more practical scoring
- Missing: competitive differentiation through ethics
- Add: positive ethical positioning, not just risk mitigation

**Revision Post (Week 9):**
```
Framework testing update: I was thinking too much like a 
risk manager, not enough like a growth investor.

Key insight: Ethical AI isn't just about avoiding problems‚Äî
it's about creating sustainable competitive advantages.

The strongest portfolio companies use ethical considerations 
to build better products and stronger moats.

Reframing the framework around "Ethical Advantage" rather 
than "Ethical Risk."
```

### Week 11-12: Revelation & Reflection

**Final Framework Components:**
1. **Ethical Advantage Assessment:** How ethics creates competitive moats
2. **Risk Mitigation Checklist:** Standard due diligence items
3. **Founder Readiness Score:** Leadership team's ethical sophistication  
4. **Portfolio Value Creation:** How to help companies improve post-investment

**Revelation Post (Week 11):**
```
Quest Complete: "AI Investment Ethics Framework" ‚úÖ

After 12 weeks of research, testing, and iteration, here's 
what I've built:

The "Ethical Advantage Framework" for AI investments

Key insight: The best AI companies don't just avoid ethical 
problems‚Äîthey turn ethical considerations into competitive 
advantages.

Framework covers:
1Ô∏è‚É£ Competitive moat analysis through ethical positioning
2Ô∏è‚É£ Technical and social risk assessment  
3Ô∏è‚É£ Founder/team ethical sophistication evaluation
4Ô∏è‚É£ Post-investment value creation roadmap

Full framework available here: [link to detailed document]

Huge thanks to [names 5 people] for their insights.

This isn't the final word‚Äîit's version 1.0 of an evolving 
approach.

What resonates? What would you challenge or add?
```

**Reflection Post (Week 12):**
```
Reflecting on my AI Ethics Framework Quest:

üéØ About the topic:
Started thinking about ethics as risk management, ended up 
seeing it as competitive strategy. That shift changed everything.

üß† About my thinking:  
My VC bias toward "what could go wrong" nearly missed the 
bigger opportunity of "what could go right."

üîÑ About the process:
Public sharing forced clarity I never would have achieved 
privately. The comments and DMs literally shaped the final 
framework.

üìä About judgment:
Most valuable learning: Ask portfolio company founders about 
their ethical frameworks BEFORE asking about their technical 
architecture. It reveals how they think about hard problems.

For anyone building investment frameworks: Start with conversations, 
not spreadsheets.

Next Quest: Exploring how to measure "ethical advantage" in 
our portfolio company KPIs.

Thanks to this community for making me a better investor. üôè
```

---

## Outcomes

### Primary Artifacts Created:
- **"Ethical Advantage Framework"** - 15-page document with worksheets
- **Founder Interview Guide** - Set of questions for due diligence  
- **Portfolio Value Creation Playbook** - Post-investment ethical guidance

### Quantifiable Results:
- **LinkedIn Engagement:** 12 posts, 400+ likes, 80+ comments, 15 meaningful DMs
- **Framework Usage:** Applied to 8 deals, influenced 2 investment decisions  
- **Network Growth:** Connected with 12 new industry experts
- **Portfolio Impact:** 3 portfolio companies requested framework for self-assessment

### Unexpected Opportunities:
- **Speaking Invitation:** Asked to present at AI investor conference
- **Media Coverage:** Framework mentioned in TechCrunch article about responsible AI investing
- **Fund Differentiation:** Now part of fund's LP presentation materials
- **Industry Recognition:** Referenced by other VCs in their own posts

### Personal Learning:
- **Domain Expertise:** Became fund's go-to person for AI ethics questions
- **Network Expansion:** Connected with academic researchers and policy experts
- **Public Voice:** Established reputation for thoughtful analysis of AI trends
- **Better Judgment:** Learned to balance idealism with practical business considerations

---

## Lessons for Other Quest Leaders

### What Worked Well:
1. **Starting with uncertainty:** Admitting I didn't have answers created better engagement than claiming expertise
2. **Regular sharing cadence:** Weekly posts kept momentum and accountability
3. **Real-world testing:** Using live deals made the framework practical, not theoretical
4. **Community input:** The best ideas came from comments and DMs, not my research

### What I'd Do Differently:
1. **More founder interviews:** Should have talked to 10+ founders, not just 3
2. **Earlier testing:** Could have started applying framework to deals by week 4
3. **Broader outreach:** Should have engaged more with academic community earlier

### Advice for Similar Quests:
1. **Pick something you're genuinely curious about** - fake curiosity shows
2. **Test with real decisions** - frameworks that aren't battle-tested aren't useful
3. **Share the messy middle** - your struggles are more valuable than your successes
4. **Follow the energy** - when people engage, dig deeper into those topics

---

## Framework Adoption

### Within the Fund:
- All partners now use framework for AI deal evaluation
- Added ethical considerations to standard due diligence checklist
- Influenced fund's next thesis development

### Industry Impact:
- Framework downloaded 200+ times in first month
- Adapted by 3 other funds (with attribution)
- Influenced AI company due diligence best practices discussion

### Ongoing Evolution:
The framework continues to evolve based on:
- New AI regulations and guidelines
- Portfolio company feedback and case studies  
- Industry developments and competitive dynamics
- Academic research on AI ethics and governance

---

*This case study demonstrates how the LBEiP framework can transform individual learning into industry-wide value creation. The key is committing to public learning and building something useful for others.* 